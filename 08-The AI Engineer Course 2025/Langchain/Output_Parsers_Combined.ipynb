{"cells":[{"cell_type":"code","execution_count":3,"id":"154b4bc7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"154b4bc7","executionInfo":{"status":"ok","timestamp":1759810871811,"user_tz":-330,"elapsed":4125,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}},"outputId":"76be7b99-3f62-4d6a-8e71-fec17431bea9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Name: langchain\n","Version: 0.3.27\n","Summary: Building applications with LLMs through composability\n","Home-page: \n","Author: \n","Author-email: \n","License: MIT\n","Location: /usr/local/lib/python3.12/dist-packages\n","Requires: langchain-core, langchain-text-splitters, langsmith, pydantic, PyYAML, requests, SQLAlchemy\n","Required-by: \n"]}],"source":["# First, let's check the version of langchain\n","!pip show langchain"]},{"cell_type":"code","execution_count":5,"id":"99361421","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"99361421","executionInfo":{"status":"ok","timestamp":1759810994662,"user_tz":-330,"elapsed":10200,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}},"outputId":"1395be32-8375-4728-ef3e-516fe82174c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting langchain_openai\n","  Downloading langchain_openai-0.3.35-py3-none-any.whl.metadata (2.4 kB)\n","Collecting langchain-core<1.0.0,>=0.3.78 (from langchain_openai)\n","  Downloading langchain_core-0.3.78-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: openai<3.0.0,>=1.104.2 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (1.109.1)\n","Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.11.0)\n","Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.4.31)\n","Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (8.5.0)\n","Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (1.33)\n","Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (6.0.3)\n","Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (4.15.0)\n","Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (25.0)\n","Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.11.9)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.11.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (0.11.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.104.2->langchain_openai) (4.67.1)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.32.4)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.104.2->langchain_openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain_openai) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain_openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.104.2->langchain_openai) (0.16.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.0.0)\n","Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (3.11.3)\n","Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (1.0.0)\n","Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.25.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.78->langchain_openai) (0.4.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (3.4.3)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain_openai) (2.5.0)\n","Downloading langchain_openai-0.3.35-py3-none-any.whl (75 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.3.78-py3-none-any.whl (449 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m449.6/449.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: langchain-core, langchain_openai\n","  Attempting uninstall: langchain-core\n","    Found existing installation: langchain-core 0.3.77\n","    Uninstalling langchain-core-0.3.77:\n","      Successfully uninstalled langchain-core-0.3.77\n","Successfully installed langchain-core-0.3.78 langchain_openai-0.3.35\n"]}],"source":["!pip install langchain_openai"]},{"cell_type":"code","execution_count":6,"id":"2c1f99ee","metadata":{"id":"2c1f99ee","executionInfo":{"status":"ok","timestamp":1759811013437,"user_tz":-330,"elapsed":15583,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}}},"outputs":[],"source":["# Import the required dependencies\n","from langchain_openai.chat_models import ChatOpenAI\n","from langchain_core.messages import HumanMessage"]},{"cell_type":"code","execution_count":28,"id":"794f591a","metadata":{"id":"794f591a","executionInfo":{"status":"ok","timestamp":1759811913248,"user_tz":-330,"elapsed":39,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}}},"outputs":[],"source":["# Initialize the chat model with consistent settings\n","chat = ChatOpenAI(model_name = 'deepseek/deepseek-chat-v3.1:free',\n","                  temperature = 2,\n","                  max_tokens = 100,\n","                  api_key=\"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\",\n","                  base_url=\"https://openrouter.ai/api/v1\")"]},{"cell_type":"markdown","id":"b59e5f23","metadata":{"id":"b59e5f23"},"source":["# 1. String Output Parser\n","\n"]},{"cell_type":"code","execution_count":29,"id":"9203fc26","metadata":{"id":"9203fc26","executionInfo":{"status":"ok","timestamp":1759811914273,"user_tz":-330,"elapsed":15,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}}},"outputs":[],"source":["# Import the String Output Parser\n","from langchain_core.output_parsers import StrOutputParser"]},{"cell_type":"code","execution_count":30,"id":"8bd38e91","metadata":{"id":"8bd38e91","executionInfo":{"status":"ok","timestamp":1759811915369,"user_tz":-330,"elapsed":3,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}}},"outputs":[],"source":["# Create a message asking for an interesting fact\n","message_h = HumanMessage(content = \"Can you give me an interesting fact I probably didn't know about?\")"]},{"cell_type":"code","execution_count":31,"id":"cb83c115","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cb83c115","executionInfo":{"status":"ok","timestamp":1759811925188,"user_tz":-330,"elapsed":8825,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}},"outputId":"51d0fbcc-e799-4d9f-b067-28a7c9f466b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Raw response:\n","content='Of course! Here\\'s one that often surprises people, from the realm of linguistics:\\n\\n**The word \"avocado\" comes from the Nahuatl word *āhuacatl*, which literally means \"testicle.\"**\\n\\nThe Aztecs named the fruit for its shape and the way it grows in pairs on the tree. When the Spanish encountered it, they adapted the word to the more pronounceable (for them) \"aguacate,\" which eventually became \"avocado\" in English.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 18, 'total_tokens': 118, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek/deepseek-chat-v3.1:free', 'system_fingerprint': None, 'id': 'gen-1759811913-ghJBlQGPvRVJUdR5NYo9', 'service_tier': None, 'finish_reason': 'length', 'logprobs': None} id='run--2a61cf3f-7e28-44a4-8758-5744ead378a7-0' usage_metadata={'input_tokens': 18, 'output_tokens': 100, 'total_tokens': 118, 'input_token_details': {}, 'output_token_details': {}}\n"]}],"source":["# Get the response from the chat model\n","response = chat.invoke([message_h])\n","\n","# Show the raw response\n","print(\"Raw response:\")\n","print(response)"]},{"cell_type":"code","execution_count":32,"id":"a8c00aec","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a8c00aec","executionInfo":{"status":"ok","timestamp":1759811935831,"user_tz":-330,"elapsed":9,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}},"outputId":"98a8fab6-873d-4c93-9641-46c4a7cc7fee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Parsed response:\n","Of course! Here's one that often surprises people, from the realm of linguistics:\n","\n","**The word \"avocado\" comes from the Nahuatl word *āhuacatl*, which literally means \"testicle.\"**\n","\n","The Aztecs named the fruit for its shape and the way it grows in pairs on the tree. When the Spanish encountered it, they adapted the word to the more pronounceable (for them) \"aguacate,\" which eventually became \"avocado\" in English.\n"]}],"source":["# Create and use the string output parser\n","str_output_parser = StrOutputParser()\n","response_parsed = str_output_parser.invoke(response)\n","\n","print(\"Parsed response:\")\n","print(response_parsed)"]},{"cell_type":"markdown","id":"bb5f1366","metadata":{"id":"bb5f1366"},"source":["# 2. Comma-Separated List Output Parser\n","\n","The Comma-Separated List Output Parser helps in getting responses in the form of a list, where items are separated by commas. This is particularly useful when you want to get multiple items as a structured list from the model."]},{"cell_type":"code","execution_count":33,"id":"5e8e7f3e","metadata":{"id":"5e8e7f3e","executionInfo":{"status":"ok","timestamp":1759811987943,"user_tz":-330,"elapsed":38,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}}},"outputs":[],"source":["# Import the Comma-Separated List Output Parser\n","from langchain_core.output_parsers import CommaSeparatedListOutputParser"]},{"cell_type":"code","execution_count":34,"id":"03545f2b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"03545f2b","executionInfo":{"status":"ok","timestamp":1759811991498,"user_tz":-330,"elapsed":8,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}},"outputId":"cc6b34f1-e983-4a9a-f366-725f77677a43"},"outputs":[{"output_type":"stream","name":"stdout","text":["Format Instructions:\n","Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"]}],"source":["# Create the list parser and get its format instructions\n","list_output_parser = CommaSeparatedListOutputParser()\n","print(\"Format Instructions:\")\n","print(list_output_parser.get_format_instructions())"]},{"cell_type":"code","execution_count":35,"id":"00f34d13","metadata":{"id":"00f34d13","executionInfo":{"status":"ok","timestamp":1759811993007,"user_tz":-330,"elapsed":2,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}}},"outputs":[],"source":["# Create a message asking for dog names with format instructions\n","message_h = HumanMessage(content = f'''I've recently adopted a dog. Could you suggest some dog names?\n","\n","{list_output_parser.get_format_instructions()}\n","''')"]},{"cell_type":"code","execution_count":36,"id":"bb5a4045","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bb5a4045","executionInfo":{"status":"ok","timestamp":1759811996295,"user_tz":-330,"elapsed":2049,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}},"outputId":"1cc8b8bf-856d-4752-a858-1392268605c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Raw response:\n","Bella, Luna, Charlie, Max, Milo, Bailey, Cooper, Rocky, Lucy, Daisy\n"]}],"source":["# Get response from the chat model\n","response = chat.invoke([message_h])\n","print(\"Raw response:\")\n","print(response.content)"]},{"cell_type":"code","execution_count":37,"id":"b260d07b","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b260d07b","executionInfo":{"status":"ok","timestamp":1759811997844,"user_tz":-330,"elapsed":5,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}},"outputId":"c168f8c4-b988-4c17-f9eb-55e5d66c4bc8"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Parsed response (as a list):\n","['Bella', 'Luna', 'Charlie', 'Max', 'Milo', 'Bailey', 'Cooper', 'Rocky', 'Lucy', 'Daisy']\n"]}],"source":["# Parse the response into a list\n","response_parsed = list_output_parser.invoke(response)\n","\n","print(\"\\nParsed response (as a list):\")\n","print(response_parsed)"]},{"cell_type":"markdown","id":"1e2a543f","metadata":{"id":"1e2a543f"},"source":["# 3. Datetime Output Parser\n","\n","The Datetime Output Parser is specialized in extracting and parsing datetime information from the model's responses. It ensures that dates and times are returned in a structured datetime format that can be easily used in Python."]},{"cell_type":"code","execution_count":38,"id":"2d8e56e9","metadata":{"id":"2d8e56e9","executionInfo":{"status":"ok","timestamp":1759812000618,"user_tz":-330,"elapsed":81,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}}},"outputs":[],"source":["# Import the Datetime Output Parser\n","from langchain.output_parsers import DatetimeOutputParser"]},{"cell_type":"code","execution_count":39,"id":"bd7213c2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bd7213c2","executionInfo":{"status":"ok","timestamp":1759812001346,"user_tz":-330,"elapsed":36,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}},"outputId":"86f2bcba-f393-4c34-f489-301181571cd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["DateTime Parser Format Instructions:\n","Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n","\n","Examples: 2023-07-04T14:30:00.000000Z, 1999-12-31T23:59:59.999999Z, 2025-01-01T00:00:00.000000Z\n","\n","Return ONLY this string, no other words!\n"]}],"source":["# Create the datetime parser and show its format instructions\n","date_output_parser = DatetimeOutputParser()\n","print(\"DateTime Parser Format Instructions:\")\n","print(date_output_parser.get_format_instructions())"]},{"cell_type":"code","execution_count":40,"id":"4865dae9","metadata":{"id":"4865dae9","executionInfo":{"status":"ok","timestamp":1759812003388,"user_tz":-330,"elapsed":3,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}}},"outputs":[],"source":["# Create a message asking about a historical date\n","message_h = HumanMessage(content = f'''When was the Danish poet Piet Hein born?\n","{date_output_parser.get_format_instructions()}\n","''')"]},{"cell_type":"code","execution_count":41,"id":"b52d559d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b52d559d","executionInfo":{"status":"ok","timestamp":1759812009084,"user_tz":-330,"elapsed":4098,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}},"outputId":"7b0c23fe-532d-4ffd-c4af-065fcb90d8b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Raw response:\n","Piet Hein (the Danish poet and scientist) was born on December 16, 1905.\n","\n","1905-12-16T00:00:00.000000Z\n"]}],"source":["# Get response from the chat model\n","response = chat.invoke([message_h])\n","print(\"Raw response:\")\n","print(response.content)"]},{"cell_type":"code","execution_count":43,"id":"1f954f91","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1f954f91","executionInfo":{"status":"ok","timestamp":1759812119583,"user_tz":-330,"elapsed":7,"user":{"displayName":"Basit Sachinwala","userId":"10886099917656247110"}},"outputId":"4ac526ef-3216-4f26-d30b-69048f2cb2be"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Parsed response (as datetime):\n","1905-12-16 00:00:00\n"]}],"source":["# Parse the response into a datetime object\n","# Extract only the datetime string from the response content\n","datetime_string = response.content.splitlines()[-1]\n","response_parsed = date_output_parser.invoke(datetime_string)\n","\n","print(\"\\nParsed response (as datetime):\")\n","print(response_parsed)"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}